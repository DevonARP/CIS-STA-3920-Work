y.test=factor(unlist((y.train)))
model = train(x.train,y.train,'nb',trControl=trainControl(method='cv',number=10))
warnings()
table(predict(model$finalModel, x.test)$class, y.test)
str(x.test)
str(y.test)
train=sample(3649,2100)
x.train=AOS[train,17]
y.train=AOS[train,20]
x.test=AOS[-train,17]
y.test=AOS[-train,20]
y.train=factor(unlist((y.train)))
y.test=factor(unlist((y.train)))
model = train(x.train,y.train,'nb',trControl=trainControl(method='cv',number=10))
warnings()
table(predict(model$finalModel, x.test)$class, y.test)
str(x.test)
str(y.test)
str(x.train)
str(y.train)
y.test=AOS[-train,20]
y.train=factor(unlist((y.train)))
y.test=factor(unlist((y.train)))
model = train(x.train,y.train,'nb',trControl=trainControl(method='cv',number=10))
warnings()
table(predict(model$finalModel, x.test)$class, y.test)
str(x.train)
str(y.train)
str(x.test)
str(y.test)
y.test=factor(unlist((y.test)))
model = train(x.train,y.train,'nb',trControl=trainControl(method='cv',number=10))
warnings()
table(predict(model$finalModel, x.test)$class, y.test)
str(x.train)
str(y.train)
str(x.test)
str(y.test)
y.test=factor(unlist((y.test)))
str(y.test)
y.test=AOS[-train,20]
str(y.test)
y.test=factor(unlist((y.test)))
model = train(x.train,y.train,'nb',trControl=trainControl(method='cv',number=10))
warnings()
table(predict(model$finalModel, x.test)$class, y.test)
classifier <- naiveBayes(AOS[,17], AOS[,20])
table(predict(classifier, AOS[,-17]), AOS[,5])
classifier <- naiveBayes(AOS[,117], AOS[,20])
classifier <- naiveBayes(AOS[,-17], AOS[,20])
classifier <- naiveBayes(AOS[,17], AOS[,20])
table(predict(classifier, AOS[,17]), AOS[,5])
table(predict(classifier, AOS[,17]), AOS[,20])
classifier <- naiveBayes(x.train, y.train)
table(predict(classifier, x.test), y.test)
sample(1:8,4)
sample(1:8,4)
library(tidyverse)
CIS_STA_3920_LN7_Hospital <- read_csv("C:/Users/poona/Downloads/CIS-STA 3920 LN7 Hospital.csv")
View(CIS_STA_3920_LN7_Hospital)
glm.fit=glm(Vote~MedChg+SocEnr+Medicare+SupSec,data = CIS_STA_3920_LN7_Hospital,family = binomial)
glm.fit=glm(as.factor(Vote)~MedChg+SocEnr+Medicare+SupSec,data = CIS_STA_3920_LN7_Hospital,family = binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type = "response")
glm,probs[1:4]
glm.probs[1:4]
glm.probs
glm.forecast=CIS_STA_3920_LN7_Hospital$Vote
glm.forecast=glm.probs
glm.probs[glm.probs>.5]="Obama"
glm.probs[glm.probs<.5]="McCain"
glm.probs
table(glm.probs,CIS_STA_3920_LN7_Hospital$Vote)
cm=table(glm.probs,CIS_STA_3920_LN7_Hospital$Vote)
sum(cm)
table(glm.probs,CIS_STA_3920_LN7_Hospital$Vote)
12+23/5+10
(12+23)/50
AOS <- read_csv("C:/Users/poona/Desktop/School/AOS.csv")
View(AOS)
AOS <- read_csv("C:/Users/poona/Desktop/School/AOS.csv")
View(AOS)
glm.fita=glm(as.factor(HiLoRisk)~LogR1+LogR2+LogR3,data = AOS,family = binomial)
summary(glm.fita)
glm.proba=predict(glm.fita,type = "response")
glm.proba[1:50]
View(CIS_STA_3920_LN7_Hospital)
glm.probs[glm.proba>.5]="HiRisk"
glm.probs[glm.proba<.5]="LoRisk"
table(glm.proba,AOS$HiLoRisk)
glm.proba[glm.proba>.5]="HiRisk"
glm.proba[glm.proba<.5]="LoRisk"
table(glm.proba,AOS$HiLoRisk)
glm.proba[glm.proba>=.5]="HiRisk"
glm.proba=predict(glm.fita,type = "response")
AOS <- read_csv("C:/Users/poona/Desktop/School/AOS.csv")
View(AOS)
glm.fita=glm(as.factor(HiLoRisk)~LogR1+LogR2+LogR3,data = AOS,family = binomial)
CIS_STA_3920_LN7_Hospital <- read_csv("C:/Users/poona/Downloads/CIS-STA 3920 LN7 Hospital.csv")
glm.fit=glm(as.factor(Vote)~MedChg+SocEnr+Medicare+SupSec,data = CIS_STA_3920_LN7_Hospital,family = binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type = "response")
glm.probs
glm.probs[glm.probs>.5]="Obama"
glm.probs[glm.probs<.5]="McCain"
glm.probs
table(glm.probs,CIS_STA_3920_LN7_Hospital$Vote)
(12+23)/50
AOS <- read_csv("C:/Users/poona/Desktop/School/AOS.csv")
glm.fita=glm(as.factor(HiLoRisk)~LogR1+LogR2+LogR3,data = AOS,family = binomial)
summary(glm.fita)
glm.proba=predict(glm.fita,type = "response")
glm.proba[glm.proba>=.5]="HiRisk"
glm.proba[glm.proba<.5]="LoRisk"
table(glm.proba,AOS$HiLoRisk)
AOS <- read_csv("C:/Users/poona/Desktop/School/AOS.csv")
glm.fita=glm(as.factor(HiLoRisk)~LogR1+LogR2+LogR3,data = AOS,family = binomial)
summary(glm.fita)
glm.proba=predict(glm.fita,type = "response")
glm.proba[1:50]
glm.proba[glm.proba>=.5]="HiRisk"
glm.proba[glm.proba<.5]="LoRisk"
table(glm.proba,AOS$HiLoRisk)
glm.proba[1:50]
glm.fita=glm(as.factor(HiLoRisk)~LogR1+LogR2+LogR3,data = AOS,family = binomial)
summary(glm.fita)
glm.proba=predict(glm.fita,type = "response")
glm.proba[1:50]
glm.proba[glm.proba>=.5]="HiRisk"
glm.proba[glm.proba<.5]="LoRisk"
length(is.na(AOS))
table(glm.proba,AOS$HiLoRisk)
view(glm.proba)
AOS <- read_csv("C:/Users/poona/Desktop/School/AOS.csv")
View(AOS)
glm.fita=glm(as.factor(HiLoRisk)~LogR1+LogR2+LogR3,data = AOS,family = binomial)
summary(glm.fita)
glm.proba=predict(glm.fita,type = "response")
glm.proba[1:50]
glm.proba[glm.proba>=.5]="HiRisk"
glm.proba[glm.proba<.5]="LoRisk"
table(glm.proba,AOS$HiLoRisk)
(851+796)/3648
(12+23)/50
library(tree)
install.packages("tree")
install.packages("ISLR")
install.packages("Carseats")
library(tree)
library(ISLR)
library(Carseats)
install.packages("Carseats")
install.packages("tree")
install.packages("ISLR")
install.packages("Carseats")
library(tree)
install.packages("tree")
install.packages("ISLR")
install.packages("Carseats")
library(tree)
library(ISLR)
library(Carseats)
view(Carseats)
install.packages(c("ISLR", "tree"))
install.packages(c("ISLR", "tree"))
dim(Carseats)
library(tree)
library(ISLR)
library(Carseats)
dim(Carseats)
Carseats
install.packages("tree")
install.packages("ISLR")
install.packages("Carseats")
library(tree)
library(ISLR)
library(Carseats)
dim(Carseats)
view(Carseats)
View(Carseats)
attach(Carseats)
High=ifelse(Sales<=8, "No","Yes")
Carseats=data.frame(Carseats,High)
tree.Carseats=tree(High`.-Sales,Carseats)
summary(tree.Carseats)
summary(tree.Carseats)
tree.Carseats=tree(High`.-Sales,Carseats)
tree.Carseats=tree(High~.-Sales,Carseats)
Carseats=data.frame(Carseats,High)
tree.Carseats=tree(High~-Sales,Carseats)
tree.Carseats=tree(High~.-Sales,Carseats)
summary(tree.Carseats)
tree.Carseats
tree.carseats=tree(High~.-Sales,Carseats)
library(tree)
library(ISLR)
attach(Carseats)
attach(Carseats)
install.packages("tree")
install.packages("tree")
install.packages("tree")
install.packages("ISLR")
install.packages("tree")
install.packages("ISLR")
install.packages("ISLR")
library(tree)
library(ISLR)
attach(Carseats)
High=ifelse(Sales<=8, "No","Yes")
Carseats=data.frame(Carseats,High)
tree.carseats=tree(High~.-Sales,Carseats)
tree.carseats =tree(High∼.-Sales ,Carseats )
install.packages("tree")
install.packages("ISLR")
library(tree)
library(ISLR)
attach(Carseats)
High=ifelse(Sales<=8, "No","Yes")
Carseats=data.frame(Carseats,High)
tree.carseats =tree(High∼.-Sales ,Carseats )
summary(tree.Carseats)
summary(tree.carseats)
View(Carseats)
tree.carseats=tree(as,factor(High)~.-Sales,Carseats)
tree.carseats=tree(as.factor(High)~.-Sales,Carseats)
summary(tree.carseats)
plot(tree.carseats)
plot(tree.carseats, main="Anil Poonai")
#Had to change High to a factor data type, they didn't have to do that at the time of the ISLR example using the tree package.
summary(tree.carseats)
plot(tree.carseats, main="Anil Poonai")
text(tree.carseats ,pretty =0)
text(tree.carseats ,pretty =0, Main="Anil Poonai")
text(tree.carseats ,pretty =0)
plot(tree.carseats)
text(tree.carseats ,pretty =0)
tree.carseats
set.seed (2)
train=sample (1: nrow(Carseats ), 200)
Carseats .test=Carseats [-train ,]
Carseats.test=Carseats[-train ,]
High.test=High[-train ]
tree.carseats =tree(High∼.-Sales ,Carseats ,subset =train )
tree.carseats =tree(as.factor(High)∼.-Sales ,Carseats ,subset =train )
tree.pred=predict (tree.carseats ,Carseats .test ,type =" class ")
tree.pred=predict(tree.carseats ,Carseats .test ,type =" class ")
tree.pred=predict(tree.carseats,Carseats.test,type="class")
table(tree.pred ,High.test)
(104+40)/200
set.seed (3)
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow =c(1,2))
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$size,cv.carseats$dev,type="b",Main="Anil Poonai")
par(mfrow =c(1,2))
plot(cv.carseats$size,cv.carseats$dev,type="b",Main="Anil Poonai")
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow =c(1,2))
plot(cv.carseats$size,cv.carseats$dev,type="b",Main="Anil Poonai")
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$size,cv.carseats$dev,type="b")
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow =c(1,2))
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$k,cv.carseats$dev,type="b")
prune.carseats =prune.misclass(tree.carseats,best =9)
plot(prune.carseats)
text(prune.carseats,pretty =0)
tree.pred=predict(prune.carseats,Carseats.test,type=" class ")
tree.pred=predict(prune.carseats,Carseats.test,type="class")
plot(prune.carseats)
text(prune.carseats,pretty =0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(97+58)/200
#A little better again.
prune.carseats=prune.misclass(tree.carseats,best =15)
plot(prune.carseats)
text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(102+52)/200
#Upgraded their function a bit didn't they.
#Fitting Restression Trees
library(MASS)
set.seed(1)
train=sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston=tree(medv∼.,Boston,subset=train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston,pretty=0)
cv.boston=cv.tree(tree.boston)
plot(cv.boston$size,cv.boston$dev,type=’b’)
plot(cv.boston$size,cv.boston$dev)
prune.boston=prune.tree(tree.boston,best=5)
plot(prune.boston)
text(prune.boston,pretty =0)
yhat=predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train," medv"]
plot(yhat,boston.test)
abline(0,1)
mean((yhat-boston.test)^2)
boston.test=Boston[-train," medv"]
boston.test=Boston[-train,"medv"]
plot(cv.boston$size,cv.boston$dev,type='b')
prune.boston=prune.tree(tree.boston,best=5)
plot(prune.boston)
text(prune.boston,pretty =0)
yhat=predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train,"medv"]
plot(yhat,boston.test)
abline(0,1)
mean((yhat-boston.test)^2)
set.seed(1)
train=sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston=tree(medv∼.,Boston,subset=train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston,pretty=0)
cv.boston=cv.tree(tree.boston)
plot(cv.boston$size,cv.boston$dev,type='b')
prune.boston=prune.tree(tree.boston,best=5)
plot(prune.boston)
text(prune.boston,pretty =0)
yhat=predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train,"medv"]
plot(yhat,boston.test)
abline(0,1)
mean((yhat-boston.test)^2)
plot(yhat,boston.test)
abline(0,1)
mean((yhat-boston.test)^2)
plot(yhat,boston.test,main = "Anil Poonai")
plot(yhat,boston.test,main = "Anil Poonai")
abline(0,1)
mean((yhat-boston.test)^2)
plot(cv.boston$size,cv.boston$dev,type='b')
plot(cv.boston$size,cv.boston$dev,type='b',main = "Anil Poonai")
prune.boston=prune.tree(tree.boston,best=5)
plot(prune.boston)
plot(prune.boston,main= "Anil Poonai")
text(prune.boston,pretty =0)
plot(prune.boston)
plot(tree.boston)
plot(prune.carseats)
plot(prune.carseats)
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(tree.carseats)
plot(prune.carseats)
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$size,cv.carseats$dev,type="b",main = "Anil Poonai")
plot(cv.carseats$k,cv.carseats$dev,type="b")
plot(cv.carseats$size,cv.carseats$dev,type="b",main = "Anil Poonai")
plot(cv.carseats$k,cv.carseats$dev,type="b",main = "Anil Poonai")
plot(prune.boston)
text(prune.boston,pretty =0)
yhat=predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train,"medv"]
plot(yhat,boston.test,main = "Anil Poonai")
abline(0,1)
mean((yhat-boston.test)^2)
#Fitting Classification Trees
#The tree graphs that take titles well, so my name couldn't be placed on those but all of the other graphs have my name.
install.packages("tree")
install.packages("ISLR")
library(tree)
library(ISLR)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats,High)
tree.carseats=tree(as.factor(High)~.-Sales,Carseats)
#Had to change High to a factor data type, they didn't have to do that at the time of the ISLR example using the tree package.
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats
set.seed (2)
train=sample (1:nrow(Carseats),200)
Carseats.test=Carseats[-train,]
High.test=High[-train]
tree.carseats=tree(as.factor(High)~.-Sales,Carseats,subset=train)
tree.carseats=tree(as.factor(High)~.-Sales,Carseats,subset=train)
tree.pred=predict(tree.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(104+40)/200
#A little better than the examples.
set.seed (3)
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow =c(1,2))
plot(cv.carseats$size,cv.carseats$dev,type="b",main = "Anil Poonai")
plot(cv.carseats$k,cv.carseats$dev,type="b",main = "Anil Poonai")
prune.carseats =prune.misclass(tree.carseats,best =9)
plot(prune.carseats)
text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(97+58)/200
#A little better again.
prune.carseats=prune.misclass(tree.carseats,best =15)
plot(prune.carseats)
text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(102+53)/200
#Upgraded their function a bit didn't they.
#Fitting Restression Trees
library(MASS)
set.seed(1)
train=sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston=tree(medv~.,Boston,subset=train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston,pretty=0)
cv.boston=cv.tree(tree.boston)
plot(cv.boston$size,cv.boston$dev,type='b',main = "Anil Poonai")
prune.boston=prune.tree(tree.boston,best=5)
plot(prune.boston)
text(prune.boston,pretty =0)
yhat=predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train,"medv"]
plot(yhat,boston.test,main = "Anil Poonai")
abline(0,1)
mean((yhat-boston.test)^2)
#Higher than what they got.
save.image("C:\\Users\\poona\\Desktop\\School\\CISSTA3920-Final.RData")
#AOS Classification
library(tidyverse)
AOS <- read_csv("C:/Users/poona/Desktop/School/AOS.csv")
tree.AOS=tree(as.factor(HiLoRisk)~LogR1+LogR2+LogR3,AOS)
summary(tree.AOS)
#Single Node and an error rate of 49.75%. Not too promising so far.
#Can't plot single Nodes.
set.seed(4)
train=sample(3648,2000)
AOS.test=AOS[-train,]
tree.AOS=tree(as.factor(HiLoRisk)~LogR1+LogR2+LogR3,AOS,subset = train)
tree.pred=predict(tree.AOS,AOS.test,type="class")
table(tree.pred,AOS$HiLoRisk[-train])
856/1648
#52.49 success rate
cv.AOS=cv.tree(tree.AOS,FUN = prune.misclass)
#can't cross validate as it is single noded.
#AOS Regression
tree.AOS=tree(`Adj Close`~LogR1+LogR2+LogR3,data=AOS,subset=train)
summary(tree.AOS)
plot(tree.AOS)
text(tree.AOS,pretty=0)
cv.AOS=cv.tree(tree.AOS)
plot(cv.AOS$size,cv.AOS$dev,type='b')
prune.AOS=prune.tree(tree.AOS,best=3)
plot(prune.AOS)
text(prune.AOS,pretty=0)
yhat=predict(tree.AOS,newdata=AOS[-train,])
AOS.test=AOS$`Adj Close`[-train]
plot(yhat,AOS.test)
abline(0,1)
mean((yhat-AOS.test)^2)
#355.3712
save.image("C:\\Users\\poona\\Desktop\\School\\CISSTA3920-Final.RData")
#Cardiac Classification
Cardiac <- read_csv("C:/Users/poona/Downloads/Cardiac.csv")
View(Cardiac)
Dead=ifelse(Cardiac$death==0,"Yes","No")
Cardiac=data.frame(Cardiac,Dead)
tree.Cardiac=tree(as.factor(Dead)~.-death,data=Cardiac)
summary(tree.Cardiac)
#5 Nodes and .4% error rate
plot(tree.Cardiac)
text(tree.Cardiac,pretty=0)
set.seed(5)
train=sample(558,558/2)
Cardiac.test=Cardiac[-train,]
tree.Cardiac=tree(as.factor(Dead)~.-death,data=Cardiac,subset=train)
tree.pred=predict(tree.Cardiac,Cardiac.test,type="class")
table(tree.pred,Cardiac$Dead[-train])
271/279
#97.13% success rate
cv.Cardiac=cv.tree(tree.Cardiac,FUN=prune.misclass)
names(cv.Cardiac)
par(mfrow=c(1,2))
plot(cv.Cardiac$size,cv.Cardiac$dev,type="b")
plot(cv.Cardiac$k,cv.Cardiac$dev,type="b")
prune.Cardiac=prune.misclass(tree.Cardiac,best=4)
plot(prune.Cardiac)
text(prune.Cardiac,pretty=0)
tree.pred=predict(prune.Cardiac,Cardiac.test,type="class")
table(tree.pred,Cardiac$Dead[-train])
#No difference
prune.Cardiac=prune.misclass(tree.Cardiac,best=5)
#Best can't be any bigger.
#Cardiac Regression
tree.Cardiac=tree(sbp~-sbp,data=Cardiac,subset=train)
#I'm using sdp due to a study that heavily correlates systolic blood pressure with death.
summary(tree.Cardiac)
#Single Noded so graphs won't work, neither will prune
yhat=predict(tree.Cardiac,newdata=Cardiac[-train,])
Cardiac.test=Cardiac$sbp[-train]
plot(yhat,Cardiac.test)
abline(0,1)
mean((yhat-Cardiac.test)^2)
#.01631906
save.image("C:\\Users\\poona\\Desktop\\School\\CISSTA3920-Final.RData")
